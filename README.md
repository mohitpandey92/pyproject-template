## Why do we need pyproject-template?
In general, every Data Science project has multiple codes, notebooks, scripts and plots, which are generated while working on the project's goals. Having a Git repo template to follow for a Data Science project is helpful to streamline your project development. 

Here are the benefits of using pyproject-template:
1. *standarize the file structure across the projects and users* 
   - This makes it easier to find files, scripts, and notebooks.
   - It also helps in understanding the project structure quickly.
   - It reduces the time it takes to set up a new project.
2. *wrap all the relevant Python scripts into a Python package for easy distribution.* Note that this distribution could be to different users or different compute environments for the same user.
    - This makes it easier to others to use and contribute to the project.
    - It also helps in maintaining the code in the long run.
3. *automate the setup of the project environment*
   - The template includes a `pyproject.toml` file, which makes your Python package `pip` installable.
4. *automate the code quality checks and linting*
   - The template includes a `.pre-commit-config.yaml` file, which uses pre-commit hooks to standardize linting and processing of Jupyter notebooks.
   - The template includes a github action to check whether the package passes unit tests and linting checks.
   - This ensures that the code follows the defined standards and helps in maintaining the code quality.
5. *deploy the package to a private PyPi server*
   - This allows you to host your package on a private `pypi` server, making it accessible to other organization users or compute environments without publishing it to a public server. 
   - Most of the tutorials on the web focus on publishing to a public PyPi server, which is not suitable for proprietary code.


## How to use this?

We use [cookiecutter](https://github.com/cookiecutter/cookiecutter) package to implement a customizable package. It has an automated pipeline to create package folder along with its corresponding metadata defined in `cookiecutter.json`

Please follow the instructions given below:

``` 
conda env create --file environment.yml
conda activate cookiecutter_env
git clone git@github.com:mohitpandey92/pyproject-template.git
pipx run cookiecutter pyproject-template
```

## Folder structure



The folder structure should be
```
packaging_tutorial/
├── LICENSE
├── pyproject.toml
├── .pre-commit-config.yaml
├── .gitignore
├── .github/workflows/
│   └── python-package.yml
├── environment.yaml
├── README.md
├── notebooks/
├── scripts/
├── plots/
└── config/
Dockerfile
├── src/
│   └── example_package/
│       ├── __init__.py
│       └── example.py
└── tests/
```

### Description of folders


* `notebooks/` - for storing jupyter notebooks. Standard naming convention of `yyyymmdd_<author>_<notebook title>`. For prototype notebooks include `_prototype`
* `scripts/` - Directory to store scripts for any sort of installation or processing. This could be to run models or scripts that do not belong to the python library.
* `plots/` - Store plots generated by script in scripts/ or notebook in `notebooks/`
* `.github/workflows/` - Contains the Github Action workflow file `python-package.yml` that runs on every push to the repository. This file is responsible for running tests and linting checks on the code in `src/example_package/` and `tests/`.
* `tests/` - For test scripts that would be automatically run by `pytest` to ensure that the code in `src/example_package/` works as expected. This tests can be run using Github Actions on every push to the repository.
* `src/example_package/` - This is the main Python package that you will be developing. It contains:
  * `__init__.py` - This file makes the directory a Python package. It can be empty or contain package-level docstring.
  * `main.py` - This is an example Python script that contains functions or classes that you want to include in your package.
* `configs/` - To store any config files specific to the models. Maintain same directory structure in `example_package`
* `.pre-commit-config.yaml` - Using [pre-commit](https://pre-commit.com/) hooks to standardize linting and processing of jupyter notebooks.
* `.gitignore` - a minimal gitignore that ignores data files, VS code configs etc. Generate this from [toptal](https://www.toptal.com/developers/gitignore)
* `environment.yaml` - Conda environment used actively for the project. micromamba recommended.
* `pyproject.toml` - Makes your python package `pip` installable!
* `Dockerfile` - Minimal Dockerfile(TBD)

## Testing

Every script in `src/example_package/script.py` should have a corresponding `tests/test_script.py`

## Local installation
If you would like to convert your Python code into a Python package that can be used widely, then follow the instructions below.
After going to the folder that contains `pyproject.toml`, use the following commands:

```
python -m build
python -m pip install dist/*.gz
```

If you would like to reinstall your package, then type:
`python -m pip install --upgrade dist/*.gz`


Note that some folks prefer specifying the package details in `setup.py`, but I recommend using `build` which I found
<a href="https://packaging.python.org/en/latest/discussions/setup-py-deprecated/">easier to use</a>.

<blockquote>
One recommended, simple, and straightforward method of building source distributions and wheels is to use the build tool with a command like python -m build which triggers the generation of both distribution formats
</blockquote>

We are using `pyproject.toml` file, which provides instructions to `build` for how to build our Python package.


Once the package has been installed, this should work anywhere in the system:

```
from example_package import example
example.add_one(2)
```

The official tutorials uses an intermediate step of publishing it to public `pypi` database, which this workflow avoids.

Source:
https://packaging.python.org/en/latest/tutorials/packaging-projects/



##  Distribute
------------------
ToDo: you would need to setup a private PyPi server (for example, see [private-pypiserver](https://testdriven.io/blog/private-pypi/) to host your package.
-------------------

> **Only do this after merging the latest pull request.**

This step will push the latest build to the PyPi server.

You can install `twine` with `pip` if necessary:
``` bash
python -m pip install twine
```
Then, once the latest PR is committed, making sure to substitute `<version>` in the code below with the version number from `pyproject.toml`, run:
``` bash
twine upload --repository-url http://xxx.com/pypi/ dist/example_package-<version>.tar.gz

```


